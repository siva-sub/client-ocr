<!DOCTYPE html>
<html>
<head>
  <title>OCR Detection Test</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.22.0/dist/ort.min.js"></script>
</head>
<body>
  <h1>OCR Detection Test</h1>
  <input type="file" id="fileInput" accept="image/*">
  <canvas id="canvas" style="border: 1px solid black;"></canvas>
  <pre id="output"></pre>

  <script>
    const output = document.getElementById('output');
    
    function log(msg) {
      output.textContent += msg + '\n';
      console.log(msg);
    }

    document.getElementById('fileInput').addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      
      const img = new Image();
      img.onload = async () => {
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.drawImage(img, 0, 0);
        
        const imageData = ctx.getImageData(0, 0, img.width, img.height);
        
        try {
          // Initialize detection model
          const detModelUrl = 'https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.3.0/onnx/PP-OCRv4/det/en_PP-OCRv3_det_infer.onnx';
          log('Loading detection model...');
          const session = await ort.InferenceSession.create(detModelUrl);
          log('Model loaded. Input names: ' + session.inputNames);
          log('Output names: ' + session.outputNames);
          
          // Preprocess image
          const { tensor, resizeInfo } = preprocessImage(imageData.data, img.width, img.height);
          
          // Run inference
          log('Running inference...');
          const results = await session.run({ x: tensor });
          log('Inference complete');
          
          // Get output
          const outputTensor = results[session.outputNames[0]];
          log('Output shape: ' + outputTensor.dims);
          log('Output type: ' + outputTensor.type);
          
          // Check output values
          const outputData = outputTensor.data;
          let min = Infinity, max = -Infinity, sum = 0;
          for (let i = 0; i < outputData.length; i++) {
            min = Math.min(min, outputData[i]);
            max = Math.max(max, outputData[i]);
            sum += outputData[i];
          }
          const avg = sum / outputData.length;
          log(`Output stats - Min: ${min}, Max: ${max}, Avg: ${avg}`);
          
          // Apply threshold and find boxes
          const thresh = 0.3;
          const boxThresh = 0.5;
          const bitmap = new Uint8Array(outputData.length);
          let countAboveThresh = 0;
          for (let i = 0; i < outputData.length; i++) {
            if (outputData[i] > thresh) {
              bitmap[i] = 255;
              countAboveThresh++;
            }
          }
          log(`Pixels above threshold (${thresh}): ${countAboveThresh} / ${outputData.length} (${(countAboveThresh/outputData.length*100).toFixed(2)}%)`);
          
          // Visualize detection map
          const [batch, channels, height, width] = outputTensor.dims;
          const detCanvas = document.createElement('canvas');
          detCanvas.width = width;
          detCanvas.height = height;
          const detCtx = detCanvas.getContext('2d');
          const detImageData = detCtx.createImageData(width, height);
          
          for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
              const idx = y * width + x;
              const val = outputData[idx] * 255;
              const pixelIdx = idx * 4;
              detImageData.data[pixelIdx] = val;
              detImageData.data[pixelIdx + 1] = val;
              detImageData.data[pixelIdx + 2] = val;
              detImageData.data[pixelIdx + 3] = 255;
            }
          }
          
          detCtx.putImageData(detImageData, 0, 0);
          document.body.appendChild(detCanvas);
          
        } catch (error) {
          log('Error: ' + error.message);
          console.error(error);
        }
      };
      
      img.src = URL.createObjectURL(file);
    });
    
    function preprocessImage(imageData, width, height) {
      // Resize to multiple of 32
      let ratio = 1.0;
      const maxSideLen = 960;
      
      if (Math.max(height, width) > maxSideLen) {
        ratio = height > width ? maxSideLen / height : maxSideLen / width;
      }
      
      let resizeH = Math.round(height * ratio);
      let resizeW = Math.round(width * ratio);
      
      resizeH = Math.round(resizeH / 32) * 32;
      resizeW = Math.round(resizeW / 32) * 32;
      
      resizeH = Math.max(resizeH, 32);
      resizeW = Math.max(resizeW, 32);
      
      log(`Resizing: ${width}x${height} â†’ ${resizeW}x${resizeH}`);
      
      // Create resized image
      const canvas = new OffscreenCanvas(resizeW, resizeH);
      const ctx = canvas.getContext('2d');
      
      const inputImageData = new ImageData(new Uint8ClampedArray(imageData), width, height);
      const tempCanvas = new OffscreenCanvas(width, height);
      const tempCtx = tempCanvas.getContext('2d');
      tempCtx.putImageData(inputImageData, 0, 0);
      
      ctx.drawImage(tempCanvas, 0, 0, width, height, 0, 0, resizeW, resizeH);
      const resizedData = ctx.getImageData(0, 0, resizeW, resizeH).data;
      
      // Normalize
      const channels = 3;
      const normalized = new Float32Array(channels * resizeH * resizeW);
      
      // Use simple normalization for detection: img / 127.5 - 1.0
      for (let y = 0; y < resizeH; y++) {
        for (let x = 0; x < resizeW; x++) {
          const idx = (y * resizeW + x) * 4;
          const pixelIdx = y * resizeW + x;
          
          // Normalize to [-1, 1] range and rearrange to CHW format
          normalized[pixelIdx] = resizedData[idx] / 127.5 - 1.0;  // R
          normalized[resizeH * resizeW + pixelIdx] = resizedData[idx + 1] / 127.5 - 1.0;  // G
          normalized[2 * resizeH * resizeW + pixelIdx] = resizedData[idx + 2] / 127.5 - 1.0;  // B
        }
      }
      
      const tensor = new ort.Tensor('float32', normalized, [1, channels, resizeH, resizeW]);
      
      return { 
        tensor, 
        resizeInfo: { 
          originalWidth: width, 
          originalHeight: height,
          resizedWidth: resizeW,
          resizedHeight: resizeH,
          ratioW: resizeW / width,
          ratioH: resizeH / height
        }
      };
    }
  </script>
</body>
</html>